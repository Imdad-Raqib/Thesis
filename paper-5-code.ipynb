{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12250103,"sourceType":"datasetVersion","datasetId":7718676}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n","metadata":{}},{"cell_type":"code","source":"!pip install transformers torch pandas scikit-learn numpy tqdm","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-23T01:53:56.603Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport pandas as pd\nimport numpy as np\nfrom transformers import XLMRobertaTokenizer, XLMRobertaModel\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, f1_score, classification_report\nfrom tqdm import tqdm\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-23T01:53:56.603Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")\n\n# Set random seeds for reproducibility\ntorch.manual_seed(42)\nnp.random.seed(42)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(42)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-23T01:53:56.604Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class BanglaTextDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_length):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n    \n    def __len__(self):\n        return len(self.texts)\n    \n    def __getitem__(self, idx):\n        text = str(self.texts[idx])\n        label = self.labels[idx]\n        \n        # Tokenize text\n        encoding = self.tokenizer(\n            text,\n            truncation=True,\n            padding='max_length',\n            max_length=self.max_length,\n            return_tensors='pt'\n        )\n        \n        return {\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'label': torch.tensor(label, dtype=torch.long)\n        }","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-23T01:53:56.604Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class XLMRobertaForTextClassification(nn.Module):\n    def __init__(self, num_classes=3, model_name='xlm-roberta-large'):\n        super(XLMRobertaForTextClassification, self).__init__()\n        \n        # Load pre-trained XLM-RoBERTa model\n        self.roberta = XLMRobertaModel.from_pretrained(model_name)\n        \n        # Get hidden size from config\n        hidden_size = self.roberta.config.hidden_size\n        \n        # Classification head (as described in the paper for RoBERTa)\n        # Hidden layer with tanh activation followed by classification layer\n        self.classifier = nn.Sequential(\n            nn.Linear(hidden_size, hidden_size),\n            nn.Tanh(),\n            nn.Linear(hidden_size, num_classes)\n        )\n        \n    def forward(self, input_ids, attention_mask):\n        # Get RoBERTa outputs\n        outputs = self.roberta(\n            input_ids=input_ids,\n            attention_mask=attention_mask\n        )\n        \n        # Get the [CLS] token representation (first token)\n        cls_output = outputs.last_hidden_state[:, 0, :]\n        \n        # Pass through classification head\n        logits = self.classifier(cls_output)\n        \n        return logits","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-23T01:53:56.604Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load your dataset\n# Replace 'your_dataset.csv' with your actual file path\ndf = pd.read_csv('/kaggle/input/final-dataset/final-dataset.csv')\n\n# Map labels to integers\nlabel_map = {'positive': 0, 'negative': 1, 'neutral': 2}\ndf['label_encoded'] = df['Polarity'].map(label_map)  # Changed from 'Label' to 'Polarity'\n\n# Check if mapping was successful\nif df['label_encoded'].isnull().any():\n    print(\"Warning: Some labels couldn't be mapped. Unique values in Polarity column:\")\n    print(df['Polarity'].unique())\n    # Handle any case sensitivity issues\n    df['Polarity'] = df['Polarity'].str.lower().str.strip()\n    df['label_encoded'] = df['Polarity'].map(label_map)\n\n# Split the data (80% train, 10% validation, 10% test)\ntexts = df['Text'].values  # Text column remains the same\nlabels = df['label_encoded'].values\n\n# First split: 80% train+val, 20% test\nX_temp, X_test, y_temp, y_test = train_test_split(\n    texts, labels, test_size=0.1, random_state=42, stratify=labels\n)\n\n# Second split: 90% train, 10% val (from the 90% temp)\nX_train, X_val, y_train, y_val = train_test_split(\n    X_temp, y_temp, test_size=0.111, random_state=42, stratify=y_temp\n)\n\nprint(f\"Train size: {len(X_train)}\")\nprint(f\"Validation size: {len(X_val)}\")\nprint(f\"Test size: {len(X_test)}\")\n\n# Print label distribution\nprint(\"\\nLabel distribution in training set:\")\nunique, counts = np.unique(y_train, return_counts=True)\nfor label, count in zip(unique, counts):\n    label_name = [k for k, v in label_map.items() if v == label][0]\n    print(f\"{label_name}: {count} ({count/len(y_train)*100:.2f}%)\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-23T01:53:56.604Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Initialize tokenizer\ntokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-large')\n\n# Set max length based on your dataset\n# The paper mentions different lengths for different datasets\n# For sentiment analysis on short texts, they used 30-100 tokens\nmax_length = 100  # Adjust based on your text length\n\n# Create datasets\ntrain_dataset = BanglaTextDataset(X_train, y_train, tokenizer, max_length)\nval_dataset = BanglaTextDataset(X_val, y_val, tokenizer, max_length)\ntest_dataset = BanglaTextDataset(X_test, y_test, tokenizer, max_length)\n\n# Create data loaders\n# Paper mentions batch size of 32\nbatch_size = 32  # Reduce if you run into memory issues\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-23T01:53:56.604Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Initialize model\nmodel = XLMRobertaForTextClassification(num_classes=3)\nmodel = model.to(device)\n\n# Loss function\ncriterion = nn.CrossEntropyLoss()\n\n# Optimizer (Adam with learning rate 1e-5 as mentioned in the paper)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n\n# Number of epochs (paper mentions 10 epochs)\nnum_epochs = 10","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-23T01:53:56.604Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_epoch(model, data_loader, criterion, optimizer, device):\n    model.train()\n    total_loss = 0\n    predictions = []\n    actual_labels = []\n    \n    for batch in tqdm(data_loader, desc=\"Training\"):\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['label'].to(device)\n        \n        optimizer.zero_grad()\n        \n        outputs = model(input_ids, attention_mask)\n        loss = criterion(outputs, labels)\n        \n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item()\n        \n        _, preds = torch.max(outputs, dim=1)\n        predictions.extend(preds.cpu().numpy())\n        actual_labels.extend(labels.cpu().numpy())\n    \n    avg_loss = total_loss / len(data_loader)\n    accuracy = accuracy_score(actual_labels, predictions)\n    f1 = f1_score(actual_labels, predictions, average='weighted')\n    \n    return avg_loss, accuracy, f1\n\ndef evaluate(model, data_loader, criterion, device):\n    model.eval()\n    total_loss = 0\n    predictions = []\n    actual_labels = []\n    \n    with torch.no_grad():\n        for batch in tqdm(data_loader, desc=\"Evaluating\"):\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['label'].to(device)\n            \n            outputs = model(input_ids, attention_mask)\n            loss = criterion(outputs, labels)\n            \n            total_loss += loss.item()\n            \n            _, preds = torch.max(outputs, dim=1)\n            predictions.extend(preds.cpu().numpy())\n            actual_labels.extend(labels.cpu().numpy())\n    \n    avg_loss = total_loss / len(data_loader)\n    accuracy = accuracy_score(actual_labels, predictions)\n    f1 = f1_score(actual_labels, predictions, average='weighted')\n    \n    return avg_loss, accuracy, f1, predictions, actual_labels","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-23T01:53:56.604Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Training loop\nbest_val_accuracy = 0\nbest_model_path = 'best_xlm_roberta_bangla.pt'\n\nfor epoch in range(num_epochs):\n    print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n    print(\"-\" * 50)\n    \n    # Train\n    train_loss, train_acc, train_f1 = train_epoch(\n        model, train_loader, criterion, optimizer, device\n    )\n    print(f\"Train Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}, F1: {train_f1:.4f}\")\n    \n    # Validate\n    val_loss, val_acc, val_f1, _, _ = evaluate(\n        model, val_loader, criterion, device\n    )\n    print(f\"Val Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}, F1: {val_f1:.4f}\")\n    \n    # Save best model based on validation accuracy\n    if val_acc > best_val_accuracy:\n        best_val_accuracy = val_acc\n        torch.save(model.state_dict(), best_model_path)\n        print(f\"Best model saved with validation accuracy: {val_acc:.4f}\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-23T01:53:56.604Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load best model\nmodel.load_state_dict(torch.load(best_model_path))\n\n# Evaluate on test set\ntest_loss, test_acc, test_f1, predictions, actual_labels = evaluate(\n    model, test_loader, criterion, device\n)\n\nprint(f\"\\nTest Results:\")\nprint(f\"Test Loss: {test_loss:.4f}\")\nprint(f\"Test Accuracy: {test_acc:.4f}\")\nprint(f\"Test F1 Score: {test_f1:.4f}\")\n\n# Detailed classification report\nlabel_names = ['positive', 'negative', 'neutral']\nprint(\"\\nClassification Report:\")\nprint(classification_report(actual_labels, predictions, target_names=label_names))","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-23T01:53:56.604Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def predict_sentiment(text, model, tokenizer, device, max_length=100):\n    \"\"\"\n    Predict sentiment for a single text\n    \"\"\"\n    model.eval()\n    \n    # Tokenize\n    encoding = tokenizer(\n        text,\n        truncation=True,\n        padding='max_length',\n        max_length=max_length,\n        return_tensors='pt'\n    )\n    \n    input_ids = encoding['input_ids'].to(device)\n    attention_mask = encoding['attention_mask'].to(device)\n    \n    # Predict\n    with torch.no_grad():\n        outputs = model(input_ids, attention_mask)\n        _, prediction = torch.max(outputs, dim=1)\n    \n    # Map back to label\n    label_map_reverse = {0: 'positive', 1: 'negative', 2: 'neutral'}\n    predicted_label = label_map_reverse[prediction.item()]\n    \n    # Get probabilities\n    probabilities = torch.nn.functional.softmax(outputs, dim=1)\n    \n    return predicted_label, probabilities.cpu().numpy()[0]\n\n# Example usage\nsample_text = \"এই মডেলটি খুব ভালো কাজ করছে\"  # \"This model is working very well\"\npredicted_label, probs = predict_sentiment(sample_text, model, tokenizer, device)\nprint(f\"Text: {sample_text}\")\nprint(f\"Predicted: {predicted_label}\")\nprint(f\"Probabilities - Positive: {probs[0]:.4f}, Negative: {probs[1]:.4f}, Neutral: {probs[2]:.4f}\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-23T01:53:56.605Z"}},"outputs":[],"execution_count":null}]}